{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7fca40bb4330>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from loss import create_loss_fn\n",
    "from model import FlexNet\n",
    "from utils.data import gen_rectangular_channel_matrix, flex_graph\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, k, batch_size):\n",
    "    h_batch = gen_rectangular_channel_matrix(k, k, n, seed=13)\n",
    "    datalist = flex_graph(h_batch)\n",
    "    return DataLoader(datalist, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def train(model, optimizer, loss_fn, dataset, k, path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=device), strict=False)\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataset, 0):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = loss_fn(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 5 == 4:  # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
    "                running_loss = 0.0\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def eval_model(path, data, k=32, aggr='add'):\n",
    "    n = 5000\n",
    "    model = FlexNet(aggr)\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    new_data = iter(DataLoader(data, batch_size=n, shuffle=False)).next()\n",
    "    outs = model(new_data)\n",
    "    p, t = outs\n",
    "    t = torch.where(t >= 0.5, 1., 0.)\n",
    "    p = torch.where(p >= 0.5, 1., 0.)\n",
    "    rate = create_loss_fn(k, 1.)\n",
    "    sum_r = rate((p, t), new_data.y)\n",
    "    print(sum_r.item())\n",
    "    return -sum_r\n",
    "\n",
    "def evaluate_models(nodes):\n",
    "    perf = []\n",
    "    path_ = \"./experiments/flexible_experiment_generalization.pth\"\n",
    "    for i in nodes:\n",
    "        data = gen_rectangular_channel_matrix(i, i, 10000, seed=899)\n",
    "        data = flex_graph(data)\n",
    "        perf.append(eval_model(path=path_, data=data, k=i))\n",
    "    return perf\n",
    "\n",
    "def evaluate_perf_models(nodes):\n",
    "    perf = []\n",
    "    for i in nodes:\n",
    "        path_ =f\"./experiments/flexible_experiment_{i}_nodes.pth\"\n",
    "        data = gen_rectangular_channel_matrix(i, i, 10000, seed=899)\n",
    "        data = flex_graph(data)\n",
    "        perf.append(eval_model(path=path_, data=data, aggr='add', k=i))\n",
    "    return perf\n",
    "\n",
    "def create_and_train_model(n, batch_size, noise_var, path, lr=0.002, aggr='add'):\n",
    "    model = FlexNet(aggr)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    k = [4, 8, 12, 16, 20, 24, 28, 32]\n",
    "    dataset = []\n",
    "    for i in k:\n",
    "            dataset.append(generate_data(n, i, batch_size))\n",
    "    for j in range(30):\n",
    "        for i, val in enumerate(k):\n",
    "            loss_fn = create_loss_fn(val, 1.)\n",
    "            train(model, optimizer, loss_fn, dataset[i], val, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = \"./experiments/flexible_experiment_generalization.pth\"\n",
    "# create_and_train_model(n=10000, batch_size=64, noise_var=1., path=path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.724555253982544\n",
      "-2.4403460025787354\n",
      "-2.8788602352142334\n",
      "-3.2358181476593018\n",
      "-3.5193471908569336\n",
      "-3.739914894104004\n",
      "-3.943530797958374\n",
      "-4.115488529205322\n"
     ]
    }
   ],
   "source": [
    "nodes = [4, 8, 12, 16, 20, 24, 28, 32]\n",
    "perf = evaluate_models(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7907705307006836\n",
      "-2.4896557331085205\n",
      "-2.9190170764923096\n",
      "-3.2618682384490967\n",
      "-3.522634744644165\n",
      "-3.7365972995758057\n",
      "-3.9261507987976074\n",
      "-4.089602947235107\n"
     ]
    }
   ],
   "source": [
    "nodes = [4, 8, 12, 16, 20, 24, 28, 32]\n",
    "perf_single = evaluate_perf_models(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = [x.item() for x in perf]\n",
    "perf_single = [x.item() for x in perf_single]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-dcf4eec86b8b4799b65cde0f1dafe7e5\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-dcf4eec86b8b4799b65cde0f1dafe7e5\") {\n      outputDiv = document.getElementById(\"altair-viz-dcf4eec86b8b4799b65cde0f1dafe7e5\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"point\": {\"size\": 60}}, \"data\": {\"name\": \"data-d106903f316405169802fd7e2bd7dd36\"}, \"mark\": {\"type\": \"line\", \"interpolate\": \"monotone\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"category\", \"legend\": {\"orient\": \"bottom-right\", \"title\": null}, \"scale\": {\"range\": [\"#e7298a\", \"#66a61e\"]}}, \"shape\": {\"type\": \"nominal\", \"field\": \"category\", \"scale\": {\"range\": [\"square\", \"circle\"]}}, \"x\": {\"type\": \"quantitative\", \"field\": \"Nodes\", \"scale\": {\"zero\": false}}, \"y\": {\"type\": \"quantitative\", \"field\": \"Sum Rate\", \"scale\": {\"zero\": false}, \"title\": \"Sum Rate (bit/s)\"}}, \"resolve\": {\"scale\": {\"color\": \"independent\", \"shape\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-d106903f316405169802fd7e2bd7dd36\": [{\"Nodes\": 4, \"category\": \"Multiple models\", \"Sum Rate\": 1.7907705307006836}, {\"Nodes\": 8, \"category\": \"Multiple models\", \"Sum Rate\": 2.4896557331085205}, {\"Nodes\": 12, \"category\": \"Multiple models\", \"Sum Rate\": 2.9190170764923096}, {\"Nodes\": 16, \"category\": \"Multiple models\", \"Sum Rate\": 3.2618682384490967}, {\"Nodes\": 20, \"category\": \"Multiple models\", \"Sum Rate\": 3.522634744644165}, {\"Nodes\": 24, \"category\": \"Multiple models\", \"Sum Rate\": 3.7365972995758057}, {\"Nodes\": 28, \"category\": \"Multiple models\", \"Sum Rate\": 3.9261507987976074}, {\"Nodes\": 32, \"category\": \"Multiple models\", \"Sum Rate\": 4.089602947235107}, {\"Nodes\": 4, \"category\": \"Single model\", \"Sum Rate\": 1.724555253982544}, {\"Nodes\": 8, \"category\": \"Single model\", \"Sum Rate\": 2.4403460025787354}, {\"Nodes\": 12, \"category\": \"Single model\", \"Sum Rate\": 2.8788602352142334}, {\"Nodes\": 16, \"category\": \"Single model\", \"Sum Rate\": 3.2358181476593018}, {\"Nodes\": 20, \"category\": \"Single model\", \"Sum Rate\": 3.5193471908569336}, {\"Nodes\": 24, \"category\": \"Single model\", \"Sum Rate\": 3.739914894104004}, {\"Nodes\": 28, \"category\": \"Single model\", \"Sum Rate\": 3.943530797958374}, {\"Nodes\": 32, \"category\": \"Single model\", \"Sum Rate\": 4.115488529205322}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = pd.DataFrame({'Nodes': nodes, 'Multiple models': perf_single,\n",
    "                       'Single model': perf })\n",
    "source = source.melt('Nodes', var_name='category', value_name='Sum Rate')\n",
    "\n",
    "chart = alt.Chart(source).mark_line(point=True, interpolate='monotone').configure_point(size=60).encode(\n",
    "    alt.X('Nodes:Q', scale=alt.Scale(zero=False)),\n",
    "    alt.Y('Sum Rate:Q', title='Sum Rate (bit/s)', scale=alt.Scale(zero=False)),\n",
    "    alt.Color('category:N', scale=alt.Scale(range=[\"#e7298a\", \"#66a61e\"]), legend=alt.Legend(orient='bottom-right', title=None)),\n",
    "    shape=alt.Shape('category:N', scale=alt.Scale(range=['square', 'circle']))\n",
    ").resolve_scale(\n",
    "    color='independent',\n",
    "    shape='independent'\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot in SVG format for viewing on Github"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![plot](https://user-images.githubusercontent.com/17931435/212999054-8edc2b3a-29b3-4039-9262-97dae02d9faa.svg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}