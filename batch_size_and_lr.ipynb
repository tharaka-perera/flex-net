{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f81530cb330>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from loss import create_loss_fn\n",
    "from main import create_and_train_model\n",
    "from model import FlexNet\n",
    "from utils.data import flex_graph, gen_rectangular_channel_matrix\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_models(batch_size, lr):\n",
    "    k = 32\n",
    "    data = gen_rectangular_channel_matrix(k, k, 10000, seed=11)\n",
    "    data = flex_graph(data)\n",
    "    for i in batch_size:\n",
    "        for j in lr:\n",
    "            path_ = f\"./experiments/flexible_experiment_batch_size_{i}_lr_{j}.pth\"\n",
    "            data_loader = DataLoader(data, batch_size=i, shuffle=True)\n",
    "            create_and_train_model(n=10000, k=32, data=data_loader, batch_size=i, noise_var=1., path=path_, lr=j)\n",
    "\n",
    "\n",
    "def evaluate_models(batch_size, lr):\n",
    "    k = 32\n",
    "    data = gen_rectangular_channel_matrix(k, k, 10000, seed=899)\n",
    "    data = flex_graph(data)\n",
    "    perf = np.empty((len(batch_size), len(lr)))\n",
    "    for i, batch in enumerate(batch_size):\n",
    "        for j, rate in enumerate(lr):\n",
    "            path_ = f\"./experiments/flexible_experiment_batch_size_{batch}_lr_{rate}.pth\"\n",
    "            perf[i, j] = eval_model(path=path_, data=data).item()\n",
    "    return perf\n",
    "\n",
    "def eval_model(path, data, k=32, aggr='add'):\n",
    "    n = 5000\n",
    "    model = FlexNet(aggr)\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    new_data = iter(DataLoader(data, batch_size=n, shuffle=False)).next()\n",
    "    outs = model(new_data)\n",
    "    p, t = outs\n",
    "    t = torch.where(t >= 0.5, 1., 0.)\n",
    "    p = torch.where(p >= 0.5, 1., 0.)\n",
    "    rate = create_loss_fn(k, 1.)\n",
    "    sum_r = rate((p, t), new_data.y)\n",
    "    return -sum_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: -1.387\n",
      "[1,    20] loss: -1.764\n",
      "[1,    30] loss: -2.015\n",
      "[1,    40] loss: -2.132\n",
      "[1,    50] loss: -2.290\n",
      "[1,    60] loss: -2.412\n",
      "[1,    70] loss: -2.486\n",
      "[1,    80] loss: -2.637\n",
      "[1,    90] loss: -2.601\n",
      "[1,   100] loss: -2.704\n",
      "[1,   110] loss: -2.743\n",
      "[1,   120] loss: -2.834\n",
      "[1,   130] loss: -2.939\n",
      "[1,   140] loss: -2.953\n",
      "[1,   150] loss: -3.003\n",
      "[1,   160] loss: -3.104\n",
      "[1,   170] loss: -3.169\n",
      "[1,   180] loss: -3.230\n",
      "[1,   190] loss: -3.316\n",
      "[1,   200] loss: -3.325\n",
      "[1,   210] loss: -3.371\n",
      "[1,   220] loss: -3.419\n",
      "[1,   230] loss: -3.441\n",
      "[1,   240] loss: -3.473\n",
      "[1,   250] loss: -3.547\n",
      "[1,   260] loss: -3.464\n",
      "[1,   270] loss: -3.554\n",
      "[1,   280] loss: -3.576\n",
      "[1,   290] loss: -3.585\n",
      "[1,   300] loss: -3.610\n",
      "[1,   310] loss: -3.598\n",
      "[2,    10] loss: -3.628\n",
      "[2,    20] loss: -3.708\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m512\u001B[39m, \u001B[38;5;241m1024\u001B[39m, \u001B[38;5;241m2048\u001B[39m]\n\u001B[1;32m      2\u001B[0m lr \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.001\u001B[39m, \u001B[38;5;241m0.002\u001B[39m, \u001B[38;5;241m0.004\u001B[39m, \u001B[38;5;241m0.006\u001B[39m, \u001B[38;5;241m0.008\u001B[39m, \u001B[38;5;241m0.01\u001B[39m]\n\u001B[0;32m----> 3\u001B[0m \u001B[43mtrain_multiple_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mtrain_multiple_models\u001B[0;34m(batch_size, lr)\u001B[0m\n\u001B[1;32m      7\u001B[0m path_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./experiments/flexible_experiment_batch_size_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_lr_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mj\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      8\u001B[0m data_loader \u001B[38;5;241m=\u001B[39m DataLoader(data, batch_size\u001B[38;5;241m=\u001B[39mi, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mcreate_and_train_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoise_var\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/flex-net/main.py:58\u001B[0m, in \u001B[0;36mcreate_and_train_model\u001B[0;34m(n, k, batch_size, noise_var, path, lr, data, aggr)\u001B[0m\n\u001B[1;32m     56\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlr)\n\u001B[1;32m     57\u001B[0m loss_fn \u001B[38;5;241m=\u001B[39m create_loss_fn(k, \u001B[38;5;241m1.\u001B[39m)\n\u001B[0;32m---> 58\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/flex-net/main.py:24\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, optimizer, loss_fn, dataset, k, path)\u001B[0m\n\u001B[1;32m     22\u001B[0m out \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[1;32m     23\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(out, data\u001B[38;5;241m.\u001B[39my)\n\u001B[0;32m---> 24\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     26\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/_tensor.py:363\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    356\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    357\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    361\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    362\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 363\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "lr = [0.001, 0.002, 0.004, 0.006, 0.008, 0.01]\n",
    "# train_multiple_models(batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.08904123, 4.09442091, 4.04036045, 4.03999376, 4.04334831,\n        3.96661282],\n       [4.0378933 , 4.08158112, 4.05126429, 4.03951931, 4.03462744,\n        4.03098249],\n       [4.01309204, 4.03474283, 4.05080509, 4.07147503, 4.00365257,\n        4.04746866],\n       [3.96966839, 4.06361866, 4.06947088, 4.04727745, 3.87133098,\n        4.07352304],\n       [4.00527   , 4.02116108, 4.03391075, 3.98576093, 4.02218008,\n        3.815238  ],\n       [3.96181989, 3.9712503 , 3.99372697, 4.03279305, 4.03354359,\n        3.908288  ],\n       [3.90001249, 3.94372702, 3.99829698, 3.74330854, 4.02735758,\n        4.02474499]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = evaluate_models(batch_size, lr)\n",
    "perf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(lr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-b629d5ae75134004b272cee1dc942573\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-b629d5ae75134004b272cee1dc942573\") {\n      outputDiv = document.getElementById(\"altair-viz-b629d5ae75134004b272cee1dc942573\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"rect\", \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"percent\", \"legend\": {\"format\": \".0%\"}, \"title\": \"Performance\"}, \"x\": {\"type\": \"ordinal\", \"axis\": {\"labelAngle\": 0}, \"field\": \"x\", \"title\": \"Learning Rate\"}, \"y\": {\"type\": \"ordinal\", \"field\": \"y\", \"title\": \"Batch Size\"}}, \"height\": 200, \"transform\": [{\"joinaggregate\": [{\"op\": \"max\", \"field\": \"z\", \"as\": \"max\"}]}, {\"calculate\": \"datum.z / datum.max\", \"as\": \"percent\"}], \"width\": 300}, {\"mark\": \"text\", \"encoding\": {\"color\": {\"condition\": {\"value\": \"white\", \"test\": \"(datum.percent > 0.97)\"}, \"value\": \"black\"}, \"text\": {\"type\": \"quantitative\", \"field\": \"percent\", \"format\": \".1%\"}, \"x\": {\"type\": \"ordinal\", \"axis\": {\"labelAngle\": 0}, \"field\": \"x\", \"title\": \"Learning Rate\"}, \"y\": {\"type\": \"ordinal\", \"field\": \"y\", \"title\": \"Batch Size\"}}, \"transform\": [{\"joinaggregate\": [{\"op\": \"max\", \"field\": \"z\", \"as\": \"max\"}]}, {\"calculate\": \"datum.z / datum.max\", \"as\": \"percent\"}]}], \"data\": {\"name\": \"data-9bceb48575fb4c505c6c28156c1b79b3\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-9bceb48575fb4c505c6c28156c1b79b3\": [{\"x\": 0.001, \"y\": 32, \"z\": 4.089041233062744}, {\"x\": 0.002, \"y\": 32, \"z\": 4.094420909881592}, {\"x\": 0.004, \"y\": 32, \"z\": 4.040360450744629}, {\"x\": 0.006, \"y\": 32, \"z\": 4.039993762969971}, {\"x\": 0.008, \"y\": 32, \"z\": 4.04334831237793}, {\"x\": 0.01, \"y\": 32, \"z\": 3.9666128158569336}, {\"x\": 0.001, \"y\": 64, \"z\": 4.037893295288086}, {\"x\": 0.002, \"y\": 64, \"z\": 4.081581115722656}, {\"x\": 0.004, \"y\": 64, \"z\": 4.05126428604126}, {\"x\": 0.006, \"y\": 64, \"z\": 4.039519309997559}, {\"x\": 0.008, \"y\": 64, \"z\": 4.034627437591553}, {\"x\": 0.01, \"y\": 64, \"z\": 4.030982494354248}, {\"x\": 0.001, \"y\": 128, \"z\": 4.013092041015625}, {\"x\": 0.002, \"y\": 128, \"z\": 4.034742832183838}, {\"x\": 0.004, \"y\": 128, \"z\": 4.05080509185791}, {\"x\": 0.006, \"y\": 128, \"z\": 4.071475028991699}, {\"x\": 0.008, \"y\": 128, \"z\": 4.003652572631836}, {\"x\": 0.01, \"y\": 128, \"z\": 4.047468662261963}, {\"x\": 0.001, \"y\": 256, \"z\": 3.969668388366699}, {\"x\": 0.002, \"y\": 256, \"z\": 4.0636186599731445}, {\"x\": 0.004, \"y\": 256, \"z\": 4.0694708824157715}, {\"x\": 0.006, \"y\": 256, \"z\": 4.047277450561523}, {\"x\": 0.008, \"y\": 256, \"z\": 3.871330976486206}, {\"x\": 0.01, \"y\": 256, \"z\": 4.073523044586182}, {\"x\": 0.001, \"y\": 512, \"z\": 4.005270004272461}, {\"x\": 0.002, \"y\": 512, \"z\": 4.021161079406738}, {\"x\": 0.004, \"y\": 512, \"z\": 4.033910751342773}, {\"x\": 0.006, \"y\": 512, \"z\": 3.9857609272003174}, {\"x\": 0.008, \"y\": 512, \"z\": 4.022180080413818}, {\"x\": 0.01, \"y\": 512, \"z\": 3.8152379989624023}, {\"x\": 0.001, \"y\": 1024, \"z\": 3.961819887161255}, {\"x\": 0.002, \"y\": 1024, \"z\": 3.971250295639038}, {\"x\": 0.004, \"y\": 1024, \"z\": 3.993726968765259}, {\"x\": 0.006, \"y\": 1024, \"z\": 4.032793045043945}, {\"x\": 0.008, \"y\": 1024, \"z\": 4.033543586730957}, {\"x\": 0.01, \"y\": 1024, \"z\": 3.90828800201416}, {\"x\": 0.001, \"y\": 2048, \"z\": 3.900012493133545}, {\"x\": 0.002, \"y\": 2048, \"z\": 3.9437270164489746}, {\"x\": 0.004, \"y\": 2048, \"z\": 3.9982969760894775}, {\"x\": 0.006, \"y\": 2048, \"z\": 3.7433085441589355}, {\"x\": 0.008, \"y\": 2048, \"z\": 4.027357578277588}, {\"x\": 0.01, \"y\": 2048, \"z\": 4.024744987487793}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.LayerChart(...)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = pd.DataFrame({'x': x.ravel(),\n",
    "                     'y': y.ravel(),\n",
    "                     'z': perf.ravel()})\n",
    "\n",
    "base = alt.Chart(source).encode(\n",
    "    x=alt.X('x:O', title='Learning Rate', axis=alt.Axis(labelAngle=0)),\n",
    "    y=alt.Y('y:O', title='Batch Size')\n",
    ").transform_joinaggregate(\n",
    "        max='max(z)',\n",
    ").transform_calculate(\n",
    "        percent=\"datum.z / datum.max\"\n",
    ")\n",
    "\n",
    "text = base.mark_text().encode(\n",
    "    text=alt.Text('percent:Q', format='.1%'),\n",
    "    color=alt.condition(\n",
    "        alt.datum.percent > 0.97,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "color_plot = base.mark_rect().encode(\n",
    "    color=alt.Color('percent:Q',\n",
    "                    title='Performance',\n",
    "                    legend=alt.Legend(format='.0%')\n",
    "                   )\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "color_plot + text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}